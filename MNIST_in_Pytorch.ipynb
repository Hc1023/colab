{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_in_Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hc1023/colab/blob/master/MNIST_in_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaDJNIs-kId6",
        "colab_type": "text"
      },
      "source": [
        "修改自[classifier_sample]('https://github.com/Hc1023/colab/blob/master/classifier_sample.ipynb')，数据集从CIFAR变为MNIST，不同之处：1.CIFAR是三通道的而MNIST是单通道的； 2.网络的参数需要变动。\n",
        "\n",
        "同时，这是classifier_sample的进化版，全面实现了一个分类器应该做的事情，而前者只进行了训练。\n",
        "\n",
        "且可与[MNIST_in_Keras](https://github.com/Hc1023/colab/blob/master/MNIST_in_Keras.ipynb)对比\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taJts3RtNSWw",
        "colab_type": "text"
      },
      "source": [
        "## Loading MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8czg9USRgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO0pIaCgS1JK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                         shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zwFQ7pb3ZNz",
        "colab_type": "code",
        "outputId": "a7ba78e3-79aa-4d4f-cf56-915e1ff2f3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "images = images[0].numpy().squeeze(0)\n",
        "plt.imshow(images)\n",
        "plt.show()\n",
        "print('digit label:{}'.format(labels.numpy()[0]))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIQfCIrwA0ERfiAowg8ERfiBoP4fkOhlqZJwgskAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "digit label:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1uLvtbwKjn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define an averagemeter for convenience\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3N4dpguNrw7",
        "colab_type": "text"
      },
      "source": [
        "## Define a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhUnYqTHNqub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#   def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
        "#                  padding, dilation, transposed, output_padding,\n",
        "#                  groups, bias, padding_mode)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 84)\n",
        "        self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x.shape=(4,1,28,28)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        #x.shape=(4,6,24,24) -> (4,6,12,12)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #x.shape=(4,16,8,8) -> (4,16,4,4)\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAW2U-DTOlZr",
        "colab_type": "text"
      },
      "source": [
        "## Define a Loss function and optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3UuPUXFoEwK",
        "colab_type": "text"
      },
      "source": [
        "学习率大，学习速度快，使用时间点通常为刚开始训练时，副作用：1.易损失值爆炸；2.易振荡。\n",
        "\n",
        "学习率小，学习速度慢，使用时间点通常为一定轮数过后，副作用：1.易过拟合；2.收敛速度慢。\n",
        "\n",
        "在训练过程中，一般根据训练轮数设置动态变化的学习率。\n",
        "\n",
        "- 刚开始训练时：学习率以 0.01 ~ 0.001 为宜。\n",
        "- 一定轮数过后：逐渐减缓。\n",
        "- 接近训练结束：学习速率的衰减应该在100倍以上。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHngNqsCOnnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "341ec3b7-b909-41de-8970-3f554aa02b4f"
      },
      "source": [
        "import torch.optim as optim\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('device:', device)\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhWuUhfwOsaw",
        "colab_type": "text"
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h48yp5gDodzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, trainloader, optimizer, epoch):\n",
        "    losses = AverageMeter()\n",
        "    model.train()\n",
        "    begin = time.time()\n",
        "    for index, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        # get the inputs, labels\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        losses.update(float(loss.item()), inputs.size(0))\n",
        "\n",
        "    end = time.time()\n",
        "    #print(\"Epoch:{} Train set: time cost:{:.4f}\".format(epoch, end - begin))\n",
        "    print(\"Epoch:{} Train set: time cost:{:.4f}, train loss:{:.4f}\"\n",
        "         .format(epoch, end - begin, losses.avg))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUMN8-RQ85Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, testloader, optimizer, epoch):\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    correct = 0\n",
        "    for index, (inputs, labels) in enumerate(testloader, 0):\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "      loss = F.cross_entropy(outputs, labels)\n",
        "      losses.update(float(loss.item()), inputs.size(0))\n",
        "      pred = outputs.argmax(dim=1, keepdim=True)\n",
        "      correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    \n",
        "    accuracy=correct / len(testloader.dataset)\n",
        "    print('Epoch:{} Test set: Average loss: {:.4f}, Accuracy: {:.4f}\\n'.format(epoch, losses.avg, accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDFSR7NtvEsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e91c0046-0f00-4661-b246-481cf06aee4b"
      },
      "source": [
        "epochs=20\n",
        "for epoch in range(epochs):\n",
        "    train(model, device, trainloader, optimizer, epoch)\n",
        "    test(model, device, testloader, optimizer, epoch)\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 Train set: time cost:7.6884, train loss:2.2969\n",
            "Epoch:0 Test set: Average loss: 2.2647, Accuracy: 0.3722\n",
            "\n",
            "Epoch:1 Train set: time cost:7.6408, train loss:1.7562\n",
            "Epoch:1 Test set: Average loss: 1.5668, Accuracy: 0.9109\n",
            "\n",
            "Epoch:2 Train set: time cost:7.6988, train loss:1.5487\n",
            "Epoch:2 Test set: Average loss: 1.5221, Accuracy: 0.9460\n",
            "\n",
            "Epoch:3 Train set: time cost:7.5835, train loss:1.5214\n",
            "Epoch:3 Test set: Average loss: 1.5079, Accuracy: 0.9572\n",
            "\n",
            "Epoch:4 Train set: time cost:7.6437, train loss:1.5083\n",
            "Epoch:4 Test set: Average loss: 1.5007, Accuracy: 0.9633\n",
            "\n",
            "Epoch:5 Train set: time cost:7.5429, train loss:1.5008\n",
            "Epoch:5 Test set: Average loss: 1.4940, Accuracy: 0.9701\n",
            "\n",
            "Epoch:6 Train set: time cost:7.5940, train loss:1.4963\n",
            "Epoch:6 Test set: Average loss: 1.4915, Accuracy: 0.9721\n",
            "\n",
            "Epoch:7 Train set: time cost:7.6019, train loss:1.4930\n",
            "Epoch:7 Test set: Average loss: 1.4886, Accuracy: 0.9748\n",
            "\n",
            "Epoch:8 Train set: time cost:7.5899, train loss:1.4904\n",
            "Epoch:8 Test set: Average loss: 1.4879, Accuracy: 0.9751\n",
            "\n",
            "Epoch:9 Train set: time cost:7.5752, train loss:1.4884\n",
            "Epoch:9 Test set: Average loss: 1.4854, Accuracy: 0.9769\n",
            "\n",
            "Epoch:10 Train set: time cost:7.6187, train loss:1.4862\n",
            "Epoch:10 Test set: Average loss: 1.4852, Accuracy: 0.9779\n",
            "\n",
            "Epoch:11 Train set: time cost:7.7296, train loss:1.4853\n",
            "Epoch:11 Test set: Average loss: 1.4827, Accuracy: 0.9799\n",
            "\n",
            "Epoch:12 Train set: time cost:7.5698, train loss:1.4837\n",
            "Epoch:12 Test set: Average loss: 1.4831, Accuracy: 0.9798\n",
            "\n",
            "Epoch:13 Train set: time cost:7.6303, train loss:1.4825\n",
            "Epoch:13 Test set: Average loss: 1.4821, Accuracy: 0.9807\n",
            "\n",
            "Epoch:14 Train set: time cost:7.5663, train loss:1.4817\n",
            "Epoch:14 Test set: Average loss: 1.4811, Accuracy: 0.9811\n",
            "\n",
            "Epoch:15 Train set: time cost:7.6402, train loss:1.4805\n",
            "Epoch:15 Test set: Average loss: 1.4802, Accuracy: 0.9818\n",
            "\n",
            "Epoch:16 Train set: time cost:7.5517, train loss:1.4799\n",
            "Epoch:16 Test set: Average loss: 1.4790, Accuracy: 0.9829\n",
            "\n",
            "Epoch:17 Train set: time cost:7.6499, train loss:1.4792\n",
            "Epoch:17 Test set: Average loss: 1.4801, Accuracy: 0.9825\n",
            "\n",
            "Epoch:18 Train set: time cost:7.5912, train loss:1.4781\n",
            "Epoch:18 Test set: Average loss: 1.4787, Accuracy: 0.9841\n",
            "\n",
            "Epoch:19 Train set: time cost:7.6429, train loss:1.4778\n",
            "Epoch:19 Test set: Average loss: 1.4837, Accuracy: 0.9782\n",
            "\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZaUpRyMjowx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),'checkpoint.pth.tar')\n",
        "checkpoint = torch.load('checkpoint.pth.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImCEc323jskt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ad1e0c0-43a1-4a91-d9f8-98d4c3b3178c"
      },
      "source": [
        "checkpoint"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('conv1.weight',\n",
              "              tensor([[[[ 0.1120, -0.1818, -0.3815, -0.3477, -0.2356],\n",
              "                        [ 0.0778, -0.0275, -0.1055, -0.3002, -0.3463],\n",
              "                        [ 0.4291,  0.1611, -0.1824, -0.0390,  0.0178],\n",
              "                        [ 0.5688,  0.4321,  0.4097,  0.3269,  0.3142],\n",
              "                        [ 0.2474,  0.5274,  0.3679,  0.3480,  0.3795]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0421,  0.0036,  0.2248,  0.2329,  0.4233],\n",
              "                        [ 0.4835,  0.5937,  0.6797,  0.5917,  0.5610],\n",
              "                        [ 0.4331,  0.6807,  0.6013,  0.3720,  0.2819],\n",
              "                        [ 0.2986,  0.0139,  0.0739,  0.0594, -0.1047],\n",
              "                        [-0.2827,  0.0915, -0.3065, -0.2918, -0.2872]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0959, -0.1259, -0.0658,  0.0790, -0.3051],\n",
              "                        [ 0.2999, -0.0333, -0.3032, -0.1910, -0.2576],\n",
              "                        [ 0.0930,  0.0144,  0.0608, -0.0849, -0.2402],\n",
              "                        [ 0.2444,  0.2894,  0.2434,  0.2110,  0.2843],\n",
              "                        [ 0.2387,  0.2727,  0.1399,  0.4859,  0.2748]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.2666,  0.3683,  0.4873,  0.3854,  0.3382],\n",
              "                        [ 0.1265,  0.2243,  0.1021,  0.4046,  0.1660],\n",
              "                        [ 0.0590, -0.2385, -0.1436, -0.1963,  0.0616],\n",
              "                        [-0.3304, -0.1300, -0.2571, -0.1741,  0.0053],\n",
              "                        [-0.2788, -0.1482, -0.2997, -0.2178, -0.1601]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0815, -0.1176,  0.0523,  0.4772,  0.3345],\n",
              "                        [-0.1399,  0.0353,  0.2608,  0.7070,  0.4482],\n",
              "                        [ 0.1078,  0.5999,  0.6867,  0.8917,  0.5477],\n",
              "                        [ 0.2868,  0.4654,  1.0297,  0.9216,  0.2183],\n",
              "                        [ 0.3845,  0.4113,  0.6829,  0.3232,  0.4284]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0366, -0.0675,  0.0786,  0.0376,  0.0127],\n",
              "                        [-0.2777, -0.2635, -0.2519, -0.1014,  0.3716],\n",
              "                        [-0.0856, -0.0709, -0.1410,  0.3217,  0.2582],\n",
              "                        [ 0.1858,  0.1944, -0.0385,  0.3381,  0.4240],\n",
              "                        [ 0.1826,  0.1046,  0.3892,  0.2285,  0.4124]]]], device='cuda:0')),\n",
              "             ('conv1.bias',\n",
              "              tensor([ 0.0003,  0.0020,  0.0595,  0.1097, -0.0009,  0.1153], device='cuda:0')),\n",
              "             ('conv2.weight',\n",
              "              tensor([[[[ 6.3304e-02, -8.2617e-02, -2.4865e-03, -7.1467e-02, -2.7140e-02],\n",
              "                        [-1.9856e-02, -5.2929e-02, -1.3376e-02, -3.9430e-02,  7.0982e-02],\n",
              "                        [-4.3506e-02,  3.8129e-02, -7.6807e-02, -7.5121e-02, -4.0492e-02],\n",
              "                        [-5.5629e-02,  6.3489e-02, -5.7318e-02,  4.1258e-02,  4.9877e-02],\n",
              "                        [-3.4484e-02,  2.2651e-02,  7.9456e-03,  8.0502e-02, -3.2287e-02]],\n",
              "              \n",
              "                       [[-3.0783e-02,  1.8787e-02, -5.8532e-02, -1.3533e-02,  2.5398e-02],\n",
              "                        [ 3.4092e-02,  3.3722e-03,  5.8115e-03, -7.6542e-02, -3.8399e-02],\n",
              "                        [ 1.8674e-02, -7.5048e-02, -3.1195e-03, -1.0615e-02,  1.6664e-02],\n",
              "                        [-4.2931e-03, -4.5112e-02, -1.6549e-02, -4.0920e-02, -5.3644e-02],\n",
              "                        [ 6.1401e-02, -5.0188e-02, -7.1589e-02,  5.7745e-02, -1.1348e-02]],\n",
              "              \n",
              "                       [[-4.7957e-02,  5.6629e-02,  5.1383e-02, -6.2325e-02, -5.4301e-02],\n",
              "                        [ 4.1779e-02, -6.7623e-02, -3.3151e-03,  5.7611e-02,  1.8103e-02],\n",
              "                        [-2.3673e-02, -2.6115e-04,  2.6089e-02,  1.6531e-02,  4.8335e-02],\n",
              "                        [ 6.3442e-02,  3.8146e-02, -7.2893e-02,  6.6740e-02,  2.8202e-02],\n",
              "                        [-2.5506e-02, -6.7561e-02,  2.7520e-02, -2.0926e-02, -4.0809e-03]],\n",
              "              \n",
              "                       [[ 1.2020e-02, -5.0349e-02, -4.7738e-02, -3.3545e-02, -5.4565e-03],\n",
              "                        [ 1.2387e-02,  7.2116e-02, -5.4785e-02,  4.5715e-02,  4.9357e-02],\n",
              "                        [ 5.3089e-02, -7.1576e-02,  3.7083e-02, -3.5935e-03,  5.1991e-02],\n",
              "                        [-4.9051e-02, -6.6206e-02,  7.7981e-02, -1.1800e-03, -5.7272e-02],\n",
              "                        [-1.4816e-02, -1.7452e-02, -7.4983e-03, -5.7579e-02,  5.6362e-02]],\n",
              "              \n",
              "                       [[ 1.8054e-02, -7.5412e-02, -4.6388e-02, -6.2866e-02,  6.3019e-02],\n",
              "                        [-1.3648e-02,  4.6123e-02,  2.9385e-02, -6.4397e-02, -2.2399e-02],\n",
              "                        [ 2.3803e-02, -3.0121e-02, -6.5892e-03, -1.5139e-02, -6.6795e-02],\n",
              "                        [-6.7607e-02,  1.0077e-02, -5.7579e-02, -6.6380e-02, -3.1189e-02],\n",
              "                        [ 1.3407e-02,  3.6436e-02,  1.9840e-02, -3.9044e-02, -2.1896e-02]],\n",
              "              \n",
              "                       [[-3.2452e-02,  5.5480e-02, -8.6476e-03, -5.9969e-02,  3.3144e-02],\n",
              "                        [-1.2146e-02, -4.4984e-02,  5.6984e-02, -8.0995e-02, -7.6216e-02],\n",
              "                        [ 1.3849e-02,  6.0834e-02, -6.6175e-02, -3.6684e-02, -3.8176e-03],\n",
              "                        [-4.0410e-02,  1.6558e-02, -4.2458e-02, -2.3508e-02, -5.4967e-02],\n",
              "                        [-4.0236e-02, -1.2403e-02,  4.7556e-02,  5.9934e-03, -4.7246e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-7.9578e-02, -3.3954e-03, -5.9068e-02,  6.7339e-02, -1.7788e-02],\n",
              "                        [ 7.7816e-02,  7.8986e-02,  9.0989e-02,  1.0064e-01, -3.8825e-02],\n",
              "                        [-2.7971e-02, -7.2570e-02, -5.2250e-02, -5.9138e-02, -4.1916e-03],\n",
              "                        [-5.6072e-02, -4.9101e-02, -1.5911e-01, -9.3807e-02, -5.6062e-02],\n",
              "                        [ 8.7420e-02, -2.2090e-02,  8.0585e-03, -1.0883e-01, -4.8084e-02]],\n",
              "              \n",
              "                       [[ 7.9496e-02,  7.1821e-02,  1.1148e-01,  5.5102e-02,  3.7266e-02],\n",
              "                        [ 1.2840e-02, -5.9297e-02,  5.3949e-02, -1.3365e-05,  9.4993e-02],\n",
              "                        [ 7.4732e-02,  4.4858e-02,  1.9382e-01,  9.9012e-02,  1.1482e-02],\n",
              "                        [-9.6941e-04,  3.7833e-02, -1.1752e-03,  1.3680e-01,  1.2134e-01],\n",
              "                        [-1.4888e-01, -1.6094e-01, -1.4720e-01, -1.4624e-01, -2.1376e-02]],\n",
              "              \n",
              "                       [[-8.2111e-03,  2.9912e-02, -3.0687e-02,  1.8466e-02,  7.7699e-02],\n",
              "                        [ 2.2024e-02,  3.8421e-04, -2.7641e-02, -5.3911e-02,  1.0706e-01],\n",
              "                        [-1.7716e-02, -9.7260e-02, -8.5819e-02,  7.9639e-02,  5.1146e-02],\n",
              "                        [-6.4148e-03,  3.1476e-02, -1.3334e-01, -8.2260e-02, -1.2906e-01],\n",
              "                        [ 5.3251e-03, -2.8037e-02, -3.8147e-02, -3.3439e-02, -1.3551e-01]],\n",
              "              \n",
              "                       [[-4.4029e-03, -1.7702e-02,  1.0660e-01,  6.8523e-02, -9.3953e-02],\n",
              "                        [ 9.5570e-02,  4.4829e-03,  9.9119e-02,  8.7970e-02, -1.8153e-02],\n",
              "                        [ 3.4584e-02,  9.8679e-02,  1.8077e-02,  7.8187e-02, -8.0388e-02],\n",
              "                        [ 7.8636e-02,  1.0762e-01,  2.3010e-02,  6.6882e-02,  9.0853e-02],\n",
              "                        [-2.3349e-02, -1.0239e-01, -5.7104e-02,  5.0822e-02,  5.3350e-02]],\n",
              "              \n",
              "                       [[-2.0475e-02,  7.4302e-02,  2.1822e-02,  1.0466e-01,  1.3008e-01],\n",
              "                        [ 4.2732e-02, -1.7781e-02,  1.2125e-01,  1.8590e-01,  1.7963e-01],\n",
              "                        [-1.5166e-01, -5.7223e-02,  9.5700e-03,  2.1954e-01,  1.8916e-01],\n",
              "                        [-2.0772e-01, -1.5077e-01, -1.0636e-01,  6.6108e-02,  5.1200e-02],\n",
              "                        [-1.1435e-02, -1.5263e-01, -2.0258e-01, -1.5923e-01, -1.4855e-01]],\n",
              "              \n",
              "                       [[ 5.4833e-02,  1.8339e-02, -1.8191e-02,  1.7473e-02, -1.8425e-02],\n",
              "                        [ 1.0537e-02, -1.0920e-02,  9.7744e-02,  1.2241e-01, -8.0302e-02],\n",
              "                        [ 3.8336e-02, -8.8735e-02, -7.5011e-02,  1.1800e-01, -1.6361e-02],\n",
              "                        [-8.6169e-02, -5.8323e-02,  2.0537e-02, -5.4529e-02, -1.1767e-01],\n",
              "                        [ 5.9300e-02, -6.2777e-02,  1.0760e-03,  3.1410e-02, -6.8859e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.2906e-02, -1.2359e-01,  4.3590e-02,  5.0919e-02,  3.9878e-02],\n",
              "                        [-2.9292e-02, -4.6358e-02,  8.9046e-02, -1.9260e-02,  1.1825e-01],\n",
              "                        [-1.9934e-02, -2.8446e-02, -2.5995e-02,  8.7445e-03, -2.1430e-02],\n",
              "                        [-1.1167e-01, -3.5318e-02,  1.0241e-01, -9.5720e-03, -2.8400e-03],\n",
              "                        [-1.1543e-02,  3.3067e-02,  6.7664e-02,  8.4842e-02,  4.8969e-02]],\n",
              "              \n",
              "                       [[-1.2896e-01,  9.6948e-03, -1.8575e-02, -6.4585e-03,  4.6374e-02],\n",
              "                        [-5.4590e-02, -8.0618e-02,  1.2645e-01,  1.8613e-01,  7.8829e-02],\n",
              "                        [ 3.7495e-02,  1.7960e-01,  1.8600e-01,  5.1105e-02,  6.5580e-02],\n",
              "                        [ 1.1433e-01,  1.0153e-01, -8.4087e-02, -6.5214e-02, -4.2265e-02],\n",
              "                        [ 8.3339e-02, -6.5273e-02, -1.9347e-02, -3.5100e-02,  3.1948e-02]],\n",
              "              \n",
              "                       [[-5.1036e-02, -7.4662e-02,  4.5597e-02,  4.7245e-02,  5.5008e-02],\n",
              "                        [-7.7702e-03, -3.2320e-02, -2.4469e-02, -3.8226e-02,  1.1488e-01],\n",
              "                        [-7.7671e-03,  1.7610e-02, -4.1497e-02, -9.1999e-02, -6.4670e-02],\n",
              "                        [ 6.7674e-02,  1.0741e-01,  1.1155e-01,  3.1363e-03, -9.0099e-02],\n",
              "                        [-6.6265e-02, -2.8099e-02,  9.5975e-02,  1.3393e-02, -7.4320e-02]],\n",
              "              \n",
              "                       [[-3.6992e-02,  3.2606e-02, -1.0790e-01, -2.9373e-02, -5.7544e-02],\n",
              "                        [-5.0762e-02, -1.5813e-01,  3.8607e-02,  1.1435e-01, -9.8834e-03],\n",
              "                        [-1.1441e-01, -1.1492e-01, -3.0538e-02,  1.6604e-01,  1.5282e-01],\n",
              "                        [-8.7584e-02,  2.1001e-02, -4.8435e-02, -3.4158e-02, -2.2192e-02],\n",
              "                        [ 1.9687e-02, -7.2654e-04, -5.6899e-02, -7.2839e-02, -6.8202e-02]],\n",
              "              \n",
              "                       [[-8.5300e-02, -7.0213e-02,  1.0435e-01,  1.6870e-01, -1.3998e-02],\n",
              "                        [ 2.4818e-02,  8.4332e-02,  2.3935e-01,  4.2024e-02, -1.5672e-02],\n",
              "                        [ 2.3154e-01,  2.0262e-01, -1.1476e-01, -5.2751e-02, -5.2559e-02],\n",
              "                        [ 1.8722e-01, -3.3893e-02, -3.7590e-02, -1.7637e-01, -1.1234e-01],\n",
              "                        [-9.6146e-02, -4.0550e-02, -1.5512e-01, -8.5121e-02, -1.1939e-01]],\n",
              "              \n",
              "                       [[ 6.4207e-02,  6.9084e-02,  1.1743e-03,  2.0354e-03, -3.4515e-02],\n",
              "                        [ 7.1830e-02,  1.0671e-01,  9.2472e-02, -1.0476e-02, -7.6859e-02],\n",
              "                        [ 1.6108e-01,  5.6435e-02, -8.4114e-02,  1.3925e-02, -1.5810e-02],\n",
              "                        [-6.2730e-02, -5.6424e-02, -2.2054e-02,  3.3836e-02, -6.6895e-02],\n",
              "                        [-5.2991e-02,  1.6493e-03, -4.1291e-02,  6.2026e-02, -1.1695e-01]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-3.7208e-02,  1.6725e-02,  1.1767e-02,  1.1469e-01,  1.3243e-01],\n",
              "                        [-1.3075e-02, -1.2934e-01, -1.6031e-01, -4.0226e-02,  2.6397e-02],\n",
              "                        [-3.4810e-02, -3.5355e-02, -5.6384e-02,  5.1558e-03, -5.1260e-02],\n",
              "                        [-1.3374e-02,  2.8312e-02, -2.6659e-02, -5.0386e-02, -8.4115e-02],\n",
              "                        [-4.7013e-02, -4.5762e-02, -1.0986e-01, -3.7034e-02, -3.9989e-03]],\n",
              "              \n",
              "                       [[ 8.9597e-02,  1.9183e-01,  9.1290e-02,  1.4178e-01, -3.4342e-02],\n",
              "                        [ 4.1347e-02, -4.6610e-03, -1.6000e-02,  1.2135e-02,  4.7898e-04],\n",
              "                        [-1.0510e-01, -1.5273e-01,  7.6803e-02,  1.4006e-01,  7.2147e-02],\n",
              "                        [-5.1739e-02, -3.5466e-02,  1.1741e-01,  4.5841e-02, -4.7728e-03],\n",
              "                        [-3.0404e-02,  6.6570e-02, -2.6226e-03, -8.4297e-02, -3.0705e-02]],\n",
              "              \n",
              "                       [[-5.9181e-02,  4.8658e-02,  2.5263e-02,  8.7513e-02,  7.0075e-02],\n",
              "                        [ 3.1237e-02, -1.0750e-01, -9.3780e-02,  3.5437e-02,  6.7303e-02],\n",
              "                        [ 9.2228e-03, -6.8681e-02,  3.5153e-02, -2.4996e-02, -5.1989e-02],\n",
              "                        [ 8.5917e-03,  3.4023e-02, -5.5202e-02, -6.4808e-02, -5.0123e-02],\n",
              "                        [-4.6861e-02,  1.3549e-02, -7.2379e-02,  4.6636e-02,  4.4736e-02]],\n",
              "              \n",
              "                       [[ 7.4748e-02,  5.9641e-02,  8.8036e-02, -9.1546e-02,  1.9895e-02],\n",
              "                        [ 1.0922e-01,  1.3486e-01,  4.3537e-02,  1.4912e-02, -6.6425e-02],\n",
              "                        [-7.5821e-03, -2.5734e-02, -2.0258e-02, -6.8097e-03,  1.5811e-02],\n",
              "                        [ 3.8639e-02,  3.1731e-02, -4.3535e-02,  1.3112e-02, -6.7715e-02],\n",
              "                        [-5.1851e-02, -1.3047e-02, -4.7967e-02, -3.5687e-02,  1.5368e-02]],\n",
              "              \n",
              "                       [[ 2.9481e-02,  3.3711e-02,  1.5141e-01,  1.2750e-01, -1.3671e-01],\n",
              "                        [-1.6184e-01, -1.9473e-01,  1.0492e-01,  2.1270e-01, -9.7256e-02],\n",
              "                        [-1.5866e-01,  1.2297e-02,  2.2026e-01,  1.0745e-01, -1.3506e-01],\n",
              "                        [-2.8057e-02,  3.0240e-02,  3.2174e-02, -5.8098e-02, -1.1495e-01],\n",
              "                        [ 8.4089e-02, -3.5152e-02, -6.1488e-02, -1.1784e-01, -7.8439e-03]],\n",
              "              \n",
              "                       [[ 4.0845e-02,  8.0914e-02,  6.7523e-02, -1.1504e-01, -1.2421e-01],\n",
              "                        [ 1.1941e-02,  3.6961e-02,  1.4745e-02, -1.0573e-02, -1.8454e-02],\n",
              "                        [-7.6272e-02,  7.8118e-02,  1.0261e-01,  4.6054e-03, -3.3979e-02],\n",
              "                        [-3.3940e-02, -7.2505e-03,  5.7161e-02, -2.7237e-02,  5.2332e-03],\n",
              "                        [ 2.6960e-02, -8.1862e-02, -7.0536e-02, -6.3505e-02, -4.3454e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 4.0517e-02, -1.5844e-01, -1.6731e-01,  6.1937e-02,  3.0574e-02],\n",
              "                        [ 3.3413e-02, -1.6503e-01, -1.0716e-01,  6.6090e-02,  2.8371e-02],\n",
              "                        [-7.0644e-02, -1.2098e-01, -2.2690e-01, -2.3342e-02,  3.8263e-03],\n",
              "                        [ 6.1454e-02, -2.3036e-01, -1.0006e-01,  1.0960e-01,  9.6686e-02],\n",
              "                        [-1.0395e-01, -1.1069e-01,  2.3954e-02,  1.3618e-01, -8.0547e-03]],\n",
              "              \n",
              "                       [[ 1.2587e-02, -1.1396e-01,  4.8555e-02,  1.6622e-01,  1.6563e-02],\n",
              "                        [-6.3243e-02, -2.9636e-01,  1.1255e-02,  1.7732e-01, -9.7538e-02],\n",
              "                        [-1.9742e-01, -1.7158e-01,  3.4456e-02,  4.9295e-02, -1.7953e-01],\n",
              "                        [-2.2034e-02, -8.2237e-02,  3.9216e-02, -3.7079e-04, -1.1388e-01],\n",
              "                        [ 3.8166e-02, -6.0896e-02, -2.3443e-02, -1.3022e-02, -4.5407e-03]],\n",
              "              \n",
              "                       [[-2.6075e-02, -3.7629e-02, -5.9529e-02, -4.0995e-02, -6.2906e-02],\n",
              "                        [ 3.0305e-02, -1.3572e-01, -1.6969e-01,  8.8533e-02, -1.2060e-02],\n",
              "                        [-1.9591e-02, -1.5627e-01, -1.0077e-01,  3.8822e-04,  8.8918e-04],\n",
              "                        [-5.2901e-02, -1.4925e-01,  1.9270e-02,  8.6648e-02,  1.0658e-01],\n",
              "                        [-7.1244e-02, -8.6499e-02, -5.9338e-02,  1.1212e-01, -5.2474e-02]],\n",
              "              \n",
              "                       [[-4.6040e-02,  2.4635e-02, -2.2419e-03, -7.4249e-02, -8.1900e-02],\n",
              "                        [-1.1098e-02, -9.0668e-02, -1.8627e-01, -1.0299e-01, -2.1502e-02],\n",
              "                        [-1.8785e-02, -5.5070e-02, -1.4580e-01, -1.1464e-01, -2.4392e-02],\n",
              "                        [ 1.5683e-02,  7.2605e-03, -1.1603e-01, -3.3284e-02,  7.7852e-03],\n",
              "                        [-5.6980e-02,  5.4738e-03, -1.8513e-02, -5.4445e-02,  7.8156e-02]],\n",
              "              \n",
              "                       [[-6.3041e-02, -1.7490e-01,  3.9846e-01,  2.8833e-01, -9.5422e-02],\n",
              "                        [-2.1679e-01, -3.3299e-02,  5.1617e-01,  3.1407e-01, -3.4554e-01],\n",
              "                        [-2.3035e-01,  7.0638e-02,  4.4014e-01,  1.4396e-01, -2.5467e-01],\n",
              "                        [-1.6832e-01,  1.5651e-01,  2.0689e-01, -1.9883e-03, -4.9824e-02],\n",
              "                        [-4.0782e-02,  3.0679e-02,  5.2887e-02,  8.2138e-03, -1.2355e-01]],\n",
              "              \n",
              "                       [[-1.2371e-01,  2.1996e-02,  1.6800e-01, -9.0469e-02, -1.7072e-01],\n",
              "                        [-1.2998e-01,  1.4077e-01,  2.1614e-01, -1.7612e-01, -9.5282e-02],\n",
              "                        [-9.6778e-03,  1.3470e-01,  1.0576e-01, -7.2092e-02, -4.7819e-02],\n",
              "                        [-4.0276e-02,  1.4114e-01, -1.7534e-02, -8.4063e-02, -7.4550e-03],\n",
              "                        [-6.4126e-02,  2.5729e-02,  3.7126e-03,  2.1302e-02, -1.2397e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 9.7709e-02,  2.3166e-01,  2.8630e-01,  2.1913e-01,  5.5409e-02],\n",
              "                        [ 4.4452e-02, -6.5825e-02, -2.6940e-02, -1.2114e-01, -1.3305e-02],\n",
              "                        [-5.8350e-02,  5.1543e-03, -1.4328e-01, -1.2095e-01, -1.1284e-01],\n",
              "                        [ 1.4475e-01,  1.9248e-01,  5.8745e-02,  3.0332e-02, -4.1028e-02],\n",
              "                        [ 8.3470e-02,  7.4735e-02,  9.8327e-02, -7.2269e-02,  5.6014e-03]],\n",
              "              \n",
              "                       [[ 1.8623e-03, -4.6386e-02,  1.9250e-02,  1.9460e-01,  8.1896e-02],\n",
              "                        [ 1.2251e-01,  2.9420e-01,  3.4121e-01,  2.3659e-01,  1.3006e-01],\n",
              "                        [ 7.4529e-02,  5.9294e-02, -9.3629e-02, -1.4334e-01, -9.4895e-02],\n",
              "                        [-1.4942e-01, -2.2827e-01, -1.1768e-01, -1.2827e-01,  7.6596e-02],\n",
              "                        [ 5.6313e-02,  4.4765e-02,  5.7619e-02,  1.0065e-01, -4.6613e-02]],\n",
              "              \n",
              "                       [[ 1.4806e-01,  1.4921e-01,  1.7329e-01,  5.8832e-02,  6.1516e-02],\n",
              "                        [ 1.4307e-02, -8.2756e-02, -8.3734e-02, -2.5518e-02, -7.5147e-02],\n",
              "                        [ 1.1921e-02, -4.7492e-02, -6.8053e-02, -6.7798e-02, -4.1564e-02],\n",
              "                        [ 2.4986e-02,  1.5240e-01,  1.0114e-01, -8.9141e-02, -7.6551e-02],\n",
              "                        [-3.4447e-02, -1.1745e-02,  6.8716e-02,  1.8345e-02, -1.5626e-02]],\n",
              "              \n",
              "                       [[-7.3430e-02,  4.9601e-02,  7.4227e-02,  7.9329e-02, -7.5257e-03],\n",
              "                        [ 1.2030e-01,  2.0329e-01,  2.3988e-01,  1.2595e-01,  6.3289e-02],\n",
              "                        [ 1.4664e-01,  2.5260e-01,  1.4655e-01,  9.2504e-02,  9.1302e-03],\n",
              "                        [-2.5513e-02, -9.2424e-02, -8.6451e-02,  2.4135e-02, -5.4538e-02],\n",
              "                        [-4.5972e-02, -6.2017e-02,  9.0204e-03, -1.9685e-02,  7.6955e-02]],\n",
              "              \n",
              "                       [[-3.3735e-02,  2.0503e-01,  3.0240e-01,  3.0515e-01,  1.2333e-01],\n",
              "                        [-6.6652e-02,  4.9560e-02,  1.9838e-02, -1.3484e-01, -1.1387e-01],\n",
              "                        [-1.9095e-01, -4.2993e-01, -4.3746e-01, -2.3072e-01, -6.5828e-02],\n",
              "                        [-1.6628e-01, -2.4335e-01, -3.1091e-02,  2.2289e-03,  7.4307e-02],\n",
              "                        [ 9.8232e-02,  1.9093e-01,  1.9353e-01, -7.7076e-02, -1.4381e-01]],\n",
              "              \n",
              "                       [[-1.0231e-02,  5.8921e-02,  5.4686e-02,  1.6062e-01, -3.0611e-02],\n",
              "                        [-1.0043e-01, -3.3441e-03,  4.8747e-03, -1.4950e-01, -1.0728e-01],\n",
              "                        [-5.9468e-02, -7.3335e-02, -1.0751e-03,  6.7568e-02, -1.5779e-03],\n",
              "                        [ 1.9913e-04,  1.3631e-03,  1.4617e-01,  1.1113e-01, -3.9635e-02],\n",
              "                        [ 1.1565e-01,  7.1638e-03,  7.2930e-02,  1.2747e-02, -6.5363e-02]]]],\n",
              "                     device='cuda:0')),\n",
              "             ('conv2.bias',\n",
              "              tensor([ 0.0092,  0.0195,  0.0473, -0.0549, -0.0608, -0.0194,  0.0050, -0.0860,\n",
              "                      -0.0947,  0.0126, -0.0267, -0.0782, -0.0577, -0.0779,  0.0242, -0.0128],\n",
              "                     device='cuda:0')),\n",
              "             ('fc1.weight',\n",
              "              tensor([[ 1.8846e-02,  3.5108e-02, -1.9720e-02,  ...,  2.8547e-02,\n",
              "                        2.0086e-02,  6.6032e-02],\n",
              "                      [ 6.0892e-02,  5.3001e-02,  5.7835e-02,  ...,  3.9644e-02,\n",
              "                       -3.8457e-02, -4.9662e-02],\n",
              "                      [-5.8167e-02,  6.8032e-03,  2.9806e-02,  ...,  1.0136e-02,\n",
              "                       -1.7940e-02, -4.0431e-02],\n",
              "                      ...,\n",
              "                      [-1.1893e-05,  3.6821e-02,  5.8249e-02,  ..., -2.1623e-03,\n",
              "                       -2.2556e-02, -2.3212e-03],\n",
              "                      [-3.3362e-02, -5.3034e-02,  2.6386e-02,  ..., -3.2969e-02,\n",
              "                        2.1494e-03,  5.9950e-02],\n",
              "                      [ 3.6482e-02,  2.5766e-02, -4.1212e-02,  ...,  3.7112e-02,\n",
              "                        1.8042e-02, -2.3989e-03]], device='cuda:0')),\n",
              "             ('fc1.bias',\n",
              "              tensor([-0.0234, -0.0436,  0.0363,  0.0640, -0.0257, -0.0458, -0.0326,  0.0205,\n",
              "                       0.0580, -0.0031, -0.0435, -0.0135, -0.0464,  0.0179, -0.0181, -0.0489,\n",
              "                      -0.0275,  0.0522,  0.0500, -0.0148,  0.0685, -0.0191,  0.0876, -0.0244,\n",
              "                       0.0297, -0.0298,  0.0440, -0.0554, -0.0592,  0.0098,  0.0512,  0.0676,\n",
              "                      -0.0059,  0.0220, -0.0010,  0.0640,  0.0049, -0.0209, -0.0511, -0.0543,\n",
              "                      -0.0390, -0.0198,  0.0476, -0.0659, -0.0181, -0.0327,  0.0031,  0.0555,\n",
              "                       0.0481,  0.0558,  0.0214, -0.0596,  0.0111, -0.0007,  0.0253,  0.0428,\n",
              "                       0.0486,  0.0228,  0.0498, -0.0088,  0.0034,  0.0322, -0.0619,  0.0397,\n",
              "                       0.0088,  0.0165, -0.0104, -0.0292,  0.0186,  0.0270,  0.0157, -0.0667,\n",
              "                       0.0693, -0.0256, -0.0493,  0.0410, -0.0201,  0.0091, -0.0490, -0.0426,\n",
              "                       0.0589, -0.0462,  0.0429,  0.0324], device='cuda:0')),\n",
              "             ('fc2.weight',\n",
              "              tensor([[ 1.7698e-01, -7.1900e-02, -5.4912e-02, -8.5314e-02, -2.6522e-01,\n",
              "                        8.5548e-03,  6.4657e-02,  2.3454e-01, -7.5171e-02, -7.2452e-02,\n",
              "                        2.8177e-02,  5.3101e-02, -1.8400e-03, -6.9322e-02, -9.6132e-02,\n",
              "                        1.6403e-01, -3.6740e-01, -1.3562e-01, -5.4134e-02,  1.3615e-01,\n",
              "                       -1.9892e-01, -7.9579e-02, -3.3222e-01, -3.5483e-03, -4.8557e-03,\n",
              "                        3.1715e-01,  1.2050e-02, -2.2769e-02, -4.8228e-02,  1.0041e-01,\n",
              "                       -2.4039e-01,  9.9659e-02,  1.4212e-01,  2.0556e-01,  1.0725e-01,\n",
              "                       -2.9209e-02,  1.6853e-01, -5.8218e-03, -8.6678e-02,  1.0552e-01,\n",
              "                        2.1701e-02,  1.2105e-01, -6.9992e-02,  4.2603e-02,  8.5222e-02,\n",
              "                        1.3043e-01,  7.2361e-03, -1.0671e-01, -5.6629e-02,  6.9714e-02,\n",
              "                       -4.0496e-03, -9.7059e-02,  1.1442e-01,  9.3719e-02, -9.9270e-02,\n",
              "                       -2.9768e-03, -4.1169e-02, -1.3111e-02,  8.5386e-02,  2.5420e-01,\n",
              "                       -2.0821e-01, -3.1172e-02, -3.8723e-02, -1.2768e-01, -6.1410e-02,\n",
              "                        8.2972e-02,  2.9037e-01,  2.4236e-02,  1.1083e-01,  2.3491e-02,\n",
              "                        9.1488e-02,  9.1289e-02, -3.4352e-02,  2.3154e-01, -7.8078e-02,\n",
              "                        2.5583e-02,  8.7148e-02, -9.4351e-02, -3.7940e-02,  1.4648e-01,\n",
              "                        2.5845e-01,  7.7997e-02, -9.8754e-02,  2.9954e-01],\n",
              "                      [ 1.6663e-01, -3.3032e-01, -7.7374e-02, -4.4779e-02,  9.3630e-02,\n",
              "                        6.7012e-02,  1.6318e-01,  7.9402e-02, -1.4909e-01, -5.0712e-02,\n",
              "                        1.0595e-01, -1.2704e-01,  6.8506e-03,  2.7615e-02, -5.5504e-02,\n",
              "                       -1.2048e-02, -5.1102e-02, -2.8651e-02,  1.6636e-01, -4.6103e-02,\n",
              "                        3.9115e-01,  2.0477e-01,  7.9705e-02,  4.3552e-02, -1.0920e-01,\n",
              "                        5.3476e-02,  3.5531e-01,  1.5129e-01, -3.5506e-02,  8.5788e-02,\n",
              "                        1.0735e-01, -7.7002e-02,  1.0135e-01, -2.9268e-01, -1.3050e-02,\n",
              "                        2.0017e-01,  1.0978e-01,  1.8236e-02,  7.6163e-02, -1.4887e-01,\n",
              "                       -1.3846e-01,  1.4692e-01,  6.4843e-04,  8.1306e-03, -5.0146e-02,\n",
              "                        5.7834e-03,  1.7407e-02, -7.5730e-02,  9.5851e-02,  9.8891e-02,\n",
              "                       -1.4844e-01, -2.6351e-01, -1.3067e-01,  5.3538e-02,  1.9306e-01,\n",
              "                       -6.3359e-02,  1.4369e-01,  3.8643e-02, -2.8190e-01,  1.2901e-01,\n",
              "                        2.9823e-02, -5.3076e-02,  1.6998e-02,  8.6743e-02,  7.8139e-02,\n",
              "                       -1.8590e-02, -2.5348e-02,  1.0325e-01,  3.0087e-02, -3.4450e-01,\n",
              "                        1.0363e-02, -5.7487e-02, -2.9210e-02, -1.7642e-01, -5.3556e-02,\n",
              "                        1.2178e-01,  1.3511e-02, -9.5537e-02,  4.6652e-02,  1.5760e-01,\n",
              "                       -1.7629e-01,  1.7788e-01,  2.2753e-02, -2.8510e-01],\n",
              "                      [ 1.9661e-01,  4.0510e-02, -2.5749e-01,  2.1859e-01,  9.4449e-02,\n",
              "                       -7.6181e-02, -3.0441e-01, -2.6503e-01, -1.6232e-01,  2.1673e-01,\n",
              "                        1.0013e-01,  3.8435e-02, -2.2247e-01, -7.1597e-03, -3.4837e-01,\n",
              "                        1.6617e-01, -1.3086e-01,  3.5764e-01,  1.6669e-01, -7.3312e-02,\n",
              "                        1.5124e-01,  3.1606e-01, -3.0585e-01,  8.1476e-02,  2.8724e-01,\n",
              "                        3.4639e-02, -9.1686e-02,  1.1195e-01,  1.3350e-01,  2.6832e-02,\n",
              "                        2.6875e-02,  1.6313e-01, -3.0218e-02,  1.7048e-01,  3.8947e-02,\n",
              "                       -3.1427e-01, -1.7391e-01, -1.5798e-02, -2.1834e-01,  5.2181e-02,\n",
              "                        1.1700e-01,  2.0170e-01, -1.3631e-01, -5.9138e-02,  6.2532e-03,\n",
              "                        2.0486e-01,  9.2240e-02, -3.9517e-02,  1.2401e-01,  2.5984e-01,\n",
              "                       -4.4851e-02, -1.7203e-02,  4.0291e-01,  2.1130e-01,  1.2460e-01,\n",
              "                       -1.2259e-01, -2.7708e-01,  6.5851e-02, -2.5217e-02, -5.6887e-02,\n",
              "                       -1.3974e-01,  8.9652e-02,  4.8149e-02, -1.2819e-01, -8.1227e-02,\n",
              "                        2.3999e-02, -1.7894e-01, -8.3491e-02, -2.2068e-02, -2.0752e-03,\n",
              "                       -8.8976e-02,  1.3392e-01, -1.3343e-01, -1.1390e-01,  1.7239e-01,\n",
              "                        1.6083e-01,  3.9148e-02,  1.1913e-02,  3.1182e-01,  8.2188e-02,\n",
              "                        6.7897e-02, -2.5439e-01,  1.3839e-02, -1.4047e-01],\n",
              "                      [-1.7194e-01,  3.6598e-01,  1.0022e-01,  3.4583e-02, -7.8813e-02,\n",
              "                        5.1349e-02, -2.2657e-01, -1.5736e-01, -1.1288e-03, -6.9633e-02,\n",
              "                       -1.3267e-02, -2.0850e-01,  3.6749e-03,  2.1271e-02,  1.8997e-01,\n",
              "                       -2.9998e-02,  2.8235e-01,  1.9085e-01, -2.2142e-01,  1.0171e-01,\n",
              "                       -1.0992e-01,  4.4342e-02,  3.5134e-02, -8.3695e-02,  3.1191e-01,\n",
              "                       -4.2724e-01, -5.9945e-02, -8.8183e-04, -1.4303e-01,  8.0470e-02,\n",
              "                        2.2024e-02, -1.6062e-01,  1.0823e-01, -1.9135e-02, -7.2429e-02,\n",
              "                        7.6051e-02, -1.7260e-01,  2.4003e-02,  1.1385e-01,  5.9215e-02,\n",
              "                       -2.7522e-01, -4.0601e-02, -2.7794e-02, -1.9671e-02, -9.1172e-02,\n",
              "                        1.2991e-01, -7.5584e-03, -8.5957e-02,  3.7678e-02, -2.0939e-01,\n",
              "                        1.1702e-01,  1.9755e-01, -8.4240e-02, -1.9910e-01,  2.6726e-01,\n",
              "                       -2.5442e-01,  1.7588e-01,  1.7359e-02, -1.0732e-01,  1.3722e-01,\n",
              "                       -9.9937e-02,  6.7436e-03,  6.6883e-02, -3.3405e-01, -6.6724e-02,\n",
              "                        7.7942e-02, -2.2403e-01, -6.0632e-02, -2.5822e-01, -1.5459e-01,\n",
              "                       -2.7568e-02, -1.9899e-02, -2.9848e-01,  3.4988e-01, -3.9762e-02,\n",
              "                        9.1377e-02,  2.9359e-01, -1.8953e-02,  2.8495e-02,  1.2244e-01,\n",
              "                        7.7884e-02,  1.5073e-01, -2.3873e-01,  8.5639e-03],\n",
              "                      [-7.2102e-04, -1.9032e-01, -1.4332e-01,  1.0415e-01,  5.2032e-02,\n",
              "                       -8.4035e-02, -3.8292e-02,  1.2190e-01,  2.0961e-01, -1.9298e-01,\n",
              "                       -7.7647e-02,  1.8489e-01, -5.2083e-02,  5.0419e-02,  4.2637e-01,\n",
              "                        1.9104e-01,  8.0114e-02, -2.6773e-01, -2.5872e-02, -2.2895e-03,\n",
              "                       -9.7641e-02,  1.5622e-03, -1.7416e-01,  8.6499e-02, -2.4195e-01,\n",
              "                        1.3178e-01, -6.2323e-02, -1.2799e-01,  1.5754e-01,  1.0424e-01,\n",
              "                        1.5100e-01, -2.5529e-01, -4.2281e-02, -6.2561e-02,  1.3952e-01,\n",
              "                        1.5643e-01,  2.8875e-01, -7.7047e-02, -5.6780e-02,  1.2102e-01,\n",
              "                       -1.1168e-01, -2.7032e-01, -2.9224e-01,  1.0036e-01,  6.0451e-02,\n",
              "                        2.3285e-02,  9.4522e-02,  1.0748e-01,  3.6283e-01, -5.4140e-05,\n",
              "                        1.6430e-01, -3.9744e-02, -1.3574e-01,  7.6931e-02, -8.2788e-03,\n",
              "                       -1.1791e-01,  2.2985e-01, -3.8234e-02,  1.8336e-01, -1.4955e-01,\n",
              "                        1.9484e-01,  5.0371e-02,  2.9228e-02,  2.1806e-01, -8.8005e-02,\n",
              "                        1.5664e-01, -3.7950e-02,  1.3498e-01, -1.9741e-01, -1.1248e-01,\n",
              "                       -5.0989e-02,  3.9219e-02,  1.8977e-01, -2.8319e-01,  1.3451e-01,\n",
              "                       -5.1876e-02, -2.0929e-01,  6.0818e-02, -6.6023e-02, -2.4423e-02,\n",
              "                       -2.7764e-02, -2.9777e-01,  1.0757e-01, -2.3572e-01],\n",
              "                      [-8.4452e-02,  1.2426e-01,  1.2323e-01, -2.2690e-02, -1.9683e-01,\n",
              "                        4.5110e-02,  1.1421e-01,  4.6714e-02, -1.9434e-01, -9.2484e-02,\n",
              "                        9.4233e-03,  3.0776e-02, -3.4126e-02,  9.0110e-02, -1.3822e-01,\n",
              "                       -2.9779e-01,  1.4162e-01,  2.1151e-02, -5.0936e-02, -1.2832e-02,\n",
              "                        8.3686e-02, -2.5957e-01,  2.1765e-01,  3.6676e-02,  1.3428e-01,\n",
              "                       -3.2134e-01,  9.7329e-02,  2.3673e-01,  9.2873e-02, -3.3911e-02,\n",
              "                       -2.7332e-02,  6.3702e-02, -1.8303e-02, -3.8396e-02,  1.1027e-01,\n",
              "                        2.6318e-01,  7.4921e-02, -1.0013e-01,  1.1821e-01, -1.6994e-02,\n",
              "                       -9.7724e-03, -2.1487e-01,  3.2194e-01,  3.3816e-02, -6.9309e-02,\n",
              "                        1.1244e-01, -1.8068e-02, -6.1632e-02, -3.3425e-01, -2.4980e-01,\n",
              "                        6.1727e-02, -2.3012e-01,  8.1048e-02,  1.5826e-01, -1.2940e-01,\n",
              "                        2.9541e-01, -1.6614e-01, -4.1775e-03,  4.5281e-02, -2.3609e-01,\n",
              "                        2.0877e-01, -5.4616e-02,  5.4513e-04,  1.5278e-01,  1.5198e-02,\n",
              "                       -3.0059e-03,  8.6992e-02,  2.2181e-02,  8.9760e-02,  1.9759e-01,\n",
              "                        1.8849e-02, -1.3052e-02, -8.4232e-02,  2.7900e-01,  1.7352e-01,\n",
              "                       -2.4290e-01,  6.7882e-02,  9.3064e-02,  6.5374e-02, -3.2908e-01,\n",
              "                        1.3423e-02, -5.5098e-02,  1.1173e-01,  2.3685e-01],\n",
              "                      [-1.3629e-01, -3.4094e-01, -1.2998e-02, -3.4839e-01,  6.5612e-02,\n",
              "                       -4.6013e-02, -1.2876e-01,  3.1251e-01, -1.9064e-01,  1.8432e-01,\n",
              "                        4.0888e-02, -3.4483e-02, -6.0311e-02, -9.4703e-02, -2.6054e-01,\n",
              "                       -2.7093e-01, -7.5779e-02,  3.4000e-02, -4.3017e-02, -2.9233e-02,\n",
              "                       -2.3370e-01, -2.0532e-01,  4.7978e-03,  1.3495e-03, -2.9746e-01,\n",
              "                        7.8108e-03, -1.3491e-01, -5.1306e-02,  2.1217e-01,  7.4907e-02,\n",
              "                       -1.0793e-02, -1.5008e-01, -1.8584e-01, -1.0060e-01, -1.8824e-02,\n",
              "                       -9.2353e-02,  1.6651e-01, -7.8717e-02,  6.8837e-04, -2.4497e-01,\n",
              "                        9.7305e-02,  1.9525e-01, -1.0685e-01,  3.9093e-03,  3.0740e-02,\n",
              "                        4.2031e-02,  2.5432e-02,  3.1195e-01,  2.1015e-02,  1.2305e-01,\n",
              "                       -3.3356e-01,  1.6691e-01, -9.0224e-02,  1.4368e-01,  3.1622e-02,\n",
              "                        2.5459e-02, -2.8184e-01,  6.9601e-02,  3.0745e-01,  6.7204e-02,\n",
              "                        1.0617e-01, -2.3209e-02, -4.0341e-02,  2.4487e-01, -2.1293e-02,\n",
              "                        7.8252e-02,  2.7319e-02,  1.4640e-01, -1.5504e-01,  1.7665e-01,\n",
              "                        9.3767e-02,  4.0839e-02,  1.0265e-01,  2.2444e-01, -5.3728e-02,\n",
              "                       -6.1927e-02, -5.8464e-03,  1.0160e-01, -1.5822e-01, -1.0392e-01,\n",
              "                        3.2286e-02, -8.3736e-03,  2.8944e-01,  2.2419e-01],\n",
              "                      [-1.6044e-01,  1.8341e-01,  1.0358e-01,  3.4573e-02, -7.5635e-02,\n",
              "                        7.5729e-02,  1.0171e-01,  3.6845e-01, -1.8534e-02,  1.2891e-02,\n",
              "                       -4.4102e-02, -4.0496e-02,  1.6673e-01, -6.6943e-02,  3.8189e-03,\n",
              "                        3.5412e-02,  1.6318e-01, -3.7930e-02,  1.6081e-01, -5.6274e-03,\n",
              "                        1.6522e-02,  2.3526e-02,  1.4783e-01, -8.1972e-03,  7.6283e-02,\n",
              "                        3.4131e-02,  5.6704e-02,  5.5262e-02, -6.5746e-02,  1.6917e-02,\n",
              "                       -3.5950e-01,  1.9000e-01, -1.1702e-01, -9.5620e-02,  9.4618e-02,\n",
              "                       -3.5788e-01, -5.9384e-02,  3.4682e-02, -3.1452e-02,  3.4020e-01,\n",
              "                        1.1508e-01, -9.4822e-02, -2.1384e-01,  1.0381e-01, -2.5499e-02,\n",
              "                       -2.1404e-01, -6.8691e-02, -3.4932e-02, -1.9280e-01, -6.5083e-02,\n",
              "                       -1.7957e-01, -1.9571e-01,  5.7375e-02,  6.6520e-02, -2.0816e-01,\n",
              "                       -2.2709e-01,  2.4627e-01,  4.0836e-02, -2.9224e-01, -2.9209e-02,\n",
              "                       -5.2726e-02, -5.9784e-02, -5.9178e-02, -1.6153e-01,  6.4033e-03,\n",
              "                       -7.6865e-02, -1.0377e-01,  3.3424e-01,  2.0894e-01, -6.3314e-02,\n",
              "                        4.0521e-02, -7.6011e-02,  2.9707e-01, -3.4941e-01, -1.6558e-01,\n",
              "                        2.1426e-01, -7.6847e-03, -4.2165e-02,  4.2018e-01,  1.5044e-01,\n",
              "                        1.3128e-01,  1.3885e-01, -1.4210e-01, -2.5126e-01],\n",
              "                      [ 3.8825e-02,  1.7553e-01,  2.0922e-01,  9.2551e-02,  3.6352e-02,\n",
              "                       -1.0675e-02,  7.0413e-02, -3.4656e-01,  2.2716e-01,  4.8792e-02,\n",
              "                        1.0901e-01,  6.3422e-02, -2.4503e-01, -1.0120e-01,  3.5985e-02,\n",
              "                       -6.7442e-02, -1.1892e-01, -1.3337e-01, -1.0787e-01, -7.6654e-02,\n",
              "                        2.3555e-02,  7.0833e-02,  9.2997e-02,  7.6795e-02,  6.1427e-02,\n",
              "                        7.7018e-02, -2.4629e-01,  3.3544e-02,  2.6489e-01,  1.8667e-02,\n",
              "                        3.4323e-01,  1.2884e-01, -7.7680e-02, -6.5712e-02, -2.4600e-01,\n",
              "                        1.4907e-01, -2.7868e-01,  3.9242e-02,  4.4159e-02,  9.8972e-02,\n",
              "                        6.3582e-02,  2.7909e-01,  6.4322e-02, -2.6633e-02, -3.3224e-03,\n",
              "                       -1.3589e-01, -4.6286e-02, -2.8166e-01,  2.6075e-01,  1.2691e-01,\n",
              "                        4.3394e-02,  1.8558e-01,  8.9350e-02, -1.8095e-01, -1.7939e-01,\n",
              "                        1.2170e-01, -2.9646e-01,  7.2288e-03, -9.7866e-02,  1.7258e-01,\n",
              "                        2.0654e-02, -4.0371e-02, -1.0253e-01,  1.1516e-01, -5.0126e-02,\n",
              "                       -2.8126e-01,  8.2602e-02, -1.9841e-01, -1.0731e-01,  2.1206e-01,\n",
              "                        9.6525e-02, -1.2662e-01,  7.5291e-02, -1.8036e-01, -4.0408e-01,\n",
              "                       -4.1216e-02,  1.7396e-01, -8.8450e-02, -3.7531e-02,  5.2580e-02,\n",
              "                       -3.0435e-01, -2.3190e-01,  2.4995e-02,  2.7289e-01],\n",
              "                      [ 1.5661e-01,  1.0204e-01, -7.1115e-02,  1.3062e-01,  2.0693e-01,\n",
              "                        4.3713e-02,  2.9874e-01, -2.4640e-01,  4.0672e-01,  4.1230e-02,\n",
              "                       -7.7564e-03,  6.4925e-02,  8.4924e-02,  9.1740e-03, -2.6888e-02,\n",
              "                        6.1168e-02, -1.8334e-02, -3.9953e-02, -3.7187e-02, -4.1065e-02,\n",
              "                       -2.8666e-01, -2.6855e-01,  1.2628e-01, -3.1456e-02,  8.1254e-02,\n",
              "                       -4.1825e-02,  1.2117e-01, -2.1091e-01, -2.0682e-01,  6.2486e-02,\n",
              "                        1.8470e-01,  1.3046e-01,  9.0909e-02,  1.7916e-01,  9.5635e-02,\n",
              "                       -6.0606e-03,  7.7928e-02,  5.4386e-02, -1.3742e-01,  4.8511e-03,\n",
              "                        1.5276e-01, -4.9547e-01,  2.4148e-01,  2.4002e-03, -1.0115e-01,\n",
              "                       -1.7791e-01, -8.4982e-02, -2.0896e-01,  4.2462e-02, -4.9594e-02,\n",
              "                        2.6836e-01,  2.2438e-01, -1.1616e-01, -2.7763e-01, -1.1120e-01,\n",
              "                        1.9258e-01,  3.0104e-01,  5.3098e-02,  1.3495e-02,  7.0331e-02,\n",
              "                       -3.1032e-01,  4.1656e-02,  7.5071e-02,  2.8003e-01, -7.9857e-02,\n",
              "                       -2.5188e-02,  1.8527e-01, -1.6067e-02,  2.1400e-01,  1.6931e-01,\n",
              "                       -3.0910e-03,  4.8045e-02, -4.4954e-02,  2.7281e-02,  2.8135e-01,\n",
              "                       -1.9213e-01, -2.1911e-01, -3.9994e-02, -4.5585e-01,  2.8893e-04,\n",
              "                        2.1551e-01,  1.6730e-01, -3.1309e-01, -1.0742e-01]], device='cuda:0')),\n",
              "             ('fc2.bias',\n",
              "              tensor([-0.0382,  0.1668, -0.0942,  0.0714,  0.0236,  0.0103,  0.0336,  0.1194,\n",
              "                      -0.0878, -0.0185], device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    }
  ]
}